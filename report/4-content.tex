\chapter{Algorithm, Formalisation, Benchmark}\label{chap:content}
\large{Possibly another chapter focusing on better preconditions collecting?}


\section{Algorithm}
Dr. Gregor Behnke already implemented a technique for 'this' available in the PANDA-3 planner. It was used to create many IPC TO domains, though it was never published, i.e., neither described nor properties like preserving of solutions were investigated.

\begin{enumerate}
	\item Consider each method m independently, no interaction is considered.
	\item For each compound task c in the methods set of subtasks infer its (super-relaxed) preconditions and effects. 
	\item Construct a graph with possible dependencies:  
	\begin{itemize}
		\item For each add effect a of c:
			\begin{enumerate} 
				\item move all tasks with precondition a behind c 
				\item move all tasks with a delete effect in front of it
			\end{enumerate}
		\item For each delete effect d of c:
			\begin{enumerate} 
				\item move all tasks with precondition d before c %
				\item move all tasks with an add effect behind it
			\end{enumerate}
	\end{itemize}
    \item If this graph does not have a circle, choose this linearization.  [It needs to be proved that (or whether) this sacrifices solutions!]
    \item If this graph does have a circle, break the circle in a random place and choose this linearization
\end{enumerate}


\section{Formalisation}


\subsection{Formally define possibilities for linearizing a model}
Input: method with n linearizations \newline
Possible outputs:
\begin{enumerate}
	\item output: n new methods, one per linearization.(Though there are usually n=k! many linearizations if k is the number of plan steps in a method)
	\item output: m<n methods (i.e., we delete some linearizations; the interesting question is which!) 
\end{enumerate}


\subsection{Formally define solution preserving properties}
* all solutions remain (note that even if 1 method with n linearizations get transformed into all n methods, this question is still undecidable)
* at least one solution remains (again: undecidable)
* all optimal solutions remain
* at least one optimal solution remains
The report/work should answer which of these criteria is guaranteed for the translation that's investigated

 
For the beginning it might be easiest how a primitive plan can linearized to a subset of all linearizations without losing any solutions. (For some tasks it will simply not matter where they are executed -- this should be formalised. That should essentially be the POCL or PO-all criterion [note that they are not equivalent: the PO criterion will find more linearizations; see Bercher \& Olz, AAAI-2020 POPOCL] by selecting just any sequence. So the problem will be which of them select so that we don't lose anything upon upwards-propagation.)


From Bercher \& Olz, AAAI-2020 POPOCL 

\emph{POCL criterion?} A partial POCL plan P = (PS, $\prec$, CL) is called POCL plan (also POCL solution) to a planning problem if and only if every precondition is supported by a causal link and there are no causal threats.


\emph{PO criterion} We refer to a partial POCL plan P = (PS , $\prec$, CL) without causal links, i.e., CL = $\emptyset$, as a partial partially ordered (PO) plan. Due to the absence of causal links, the solution criteria are here defined directly by the desired property of every linearization being executable.

i.e. A partial PO plan P = (PS , $\prec$) is called PO plan (also PO solution) to a planning problem if and only
if every linearization is executable in the initial state and results into a goal state.
i.e. it has every necessary ordering.



\subsection{This algorithm won't always work}
This algorithm linearises all the methods to be totally ordered.
Since sub-tasks inherit the orderings of their parents, it's obviously impossible to preserve a solution that requires the interleaving of sub-tasks of parents that are already ordered with respect to each other.

Consider the simple problem:

F = \{a, b, c, g\}
$N_p$ = \{$T_A, T_B, T_C$, G\}
$N_c$ = \{AB \}
$\delta = \{ (T_A, A), (T_B, B), (T_C, C) \}$
M = $(AB,  \{ \{4,5\}, \{\}, \{(4,A), (5,B)\} \} )$
$TN_Init$ = $\{ \{0,1,2\},  \{(0,2), (1,2)\}, \{(0,AB), (1,C), (2,G)\} \}$
	
	
$S_I$ = $<a>$
	
	A = $<$pre a, del a, add c$>$
	C = $<$pre c, del c, add b$>$
	B = $<$pre b, del b, add g$>$
	G = $<$pre g, ,$>$
	
	The initial task network enforces that G is the last action.
	How do we make G executable? With the action B.
	How do we make B executable? With the action C.
	How do we make C executable? With the action A.
	How do we make A executable? It's executable in the initial state.
	Solution: A C B G.
	This is impossible to achieve by linearizing methods, since either AB before C or C before AB, both of which exclude the solution.
	Thus PO -> TO not possible this way. You would need to 
	
	We can also see, if we apply Gregor's algorithm:
	AB = $<$pre a b, del a b, add c g$>$
	A = $<$pre a, del a, add c$>$
	C = $<$pre c, del c, add b$>$
	B = $<$pre b, del b, add g$>$
	G = $<$pre g, $>$
	
	If we consider the method (Init $\implies$ \{AB, C, G\})
	AB has precondition a b, and C has add effect b, so C is moved before AB.             i.e. we add (C, AB) to $\prec$
	AB has a delete effect del a b, which doesn't affect C or G, so nothing happens here.
	AB has add effect c g, and G has prec g so G is moved after AB.	                      i.e. we add (AB, G) to $\prec$
	C has a precondition c, which is in the add effect of AB.  So AB is placed before C.   i.e. we add (AB, C) to $\prec$
	
	This produces a cycle.
	
	The essence of this example is: some sub-task C would only NEED interleaving A, C, B from another parent 
	before A and after B because of one or more of the following
	\begin{enumerate} 
		\item its precondition needs the add effect of some sub-task A from another parent (that it can't get another way)
		\item sub-task A has some precondition variable that is deleted by C (that can't be restored another way).
	\end{enumerate}
     while simultaneously also needing one or more of the following:
	\begin{enumerate} 
		\item some sub-task B from another parent has a precondition that C has in its add effect (that it can't get another way)
		\item C has in its precondition a variable in the delete effect of some sub-task B from another parent (that can't be restored another way).
	\end{enumerate}
		
	 Due to the way Gregor's algorithm collects prec/effects for a compound task, interleaving requirements are a subset of the orderings found by:

\begin{itemize}
	\item For each add effect a of c:
	\begin{enumerate} 
		\item move all tasks with precondition a behind c 
		\item move all tasks with a delete effect in front of it
	\end{enumerate}
	\item For each delete effect d of c:
	\begin{enumerate} 
		\item move all tasks with precondition d before c %
		\item move all tasks with an add effect behind it
	\end{enumerate}
\end{itemize}

	So if the interleaving is necessary, gregors algorithm will find orderings (parent(A), C) and (C, parent(B)). Since parent(A) and parent(B) are the same compund task, a cycle is formed.
	
	So requiring interleaving means that a cycle will form.
	A cycle does not always imply the solution is excluded though - due to the way the preconditons and effects are calculated, not all of the preconditions are always needed,	and not all of the effects will actually occur.
	

\subsection{Theory: So long as it doesn't have to cycle-break, algorithm will LITERALLY always work}
	 A solution that requires interleaving under the current algorithm 
	will be excluded from the set of solutions in the algorithm.
	
	As we've said before, requiring interleaving means that a cycle will form.
	By simple contrapositive, if there are no cycles to break, that implies none of the the original solutions required interleaving sub-tasks.
	The methods are linearised in a way that is essentially equivalent to using POCl causal links. That means that if \emph{every} method is linearized without using cycle-breaking, then the TO problem must preserve at least one solution if the PO problem has any?
	
	(Furthermore if there are floating tasks after gregors algorithm is applied, you can produce multiple linearizations to preserve more solutions?)
	
	\begin{enumerate}
		\item if there is no cycle, then the subtasks of this method do not require their execution to be interleaved  
		\item If it can't be solved when no cycles were broken, then the original couldn't be solved either (needs proof, by induction (and contradiction)?)		
	\end{enumerate}



	1) Methods don't have any application preconditions except for what task it applies to.
	Why can't you just randomly decompose the initial task network into primitives and get a plan?
	\begin{enumerate}
		\item Cycles in decomposition process. This is clearly a problem that  
		\item \textbf{The proposed seq of primitives leads to a state where the next desired action is not executable.}
	\end{enumerate}

	
	
	2) Assume that the original PO plan did have a solution. Let the solution take the form $a_0 ... a_n$. The preconditions, add, and delete effects are pre($a_i$), add($a_i$), del($a_i$).	This means that for every variable in a precondition of an action in the solution is in an add effect of another action OR present in the initial state.
	
	Suppose we apply the methods that would lead to a solution in the PO version. Then we have one of the possible linearizations that could have resulted
	from the PO version. We now prove that this also leads to a solution?
	
	Because of how the algorithm collects pre/eff for cmpd tasks, the subtasks each have a subset of the parents pre/eff. The union of all these prec/eff sets equal the compound tasks preconditions/effects.
	
	Eventually, some of the sub-tasks decomposed to will be primitive tasks. These will still be a subset of the parents pre/eff, such that their union is equal to their parents pre/eff.
	Assuming that the method linearization for this method did not have cycles, that means that none of the pre/eff of these sub-tasks conflict.
	If they don't meet the pre/eff of the next action, neither could the PO version. 
	
	???
	Therefore it must be a solution??
	
	
	
\subsection{Even when it does have to cycle break it will sometimes work}
(Again) A cycle does not always imply the solution is excluded though - due to the way the preconditons and effects are calculated, not all of the preconditions are always needed,	and not all of the effects will actually occur.  Thus the orderings imposed as a result of these preconditions and effects will sometimes not be necessary for a solution.

If you randomly break the cycle by removing an ordering like that (one from a unneeded precondition or incorrect effect) it will still work.


For another, the 'precondition needed by a compound task' may sometimes be possible to satisfy internally. The specific variable
that is required may be added by a sub-task of the parent. In that case, it may not need the ordering between itself and another compound task.


\subsection{For some tasks it doesn't matter where they are executed}
From content-notes: That should essentially be the POCL or PO-all criterion??
If the task has no causal links, it won't matter where they are executed.

A task can execute anywhere in any possible plan if: 
\begin{itemize}
\item 1) The variables in its precondition are present in the initial state, and there are no actions that can delete it.
\item 2) It only adds variables already present in the initial state, and there are no actions that can delete those variables
\item 2b) It only adds variables that other actions do not rely on
\item 3) It only deletes variables that don't hold in the initial state, and there are no actions that can add those variables
\item 3b) It only deletes variables that other actions do not rely on.
\end{itemize}


Additionally, it can execute anywhere in a specific plan if:
\begin{itemize}
\item 1a) the variables in its precondition are present in the initial state, and no actions in the plan delete it.
\item 2c) it adds variables that another action already adds before it does, and is not deleted again.
\end{itemize} 

R.g. if gregor's algorithm deems it a floating task (no orderings imposed on it),
it can definitely be executed anywhere.


\section{Empirical Evaluation}

To prove that our technique is beneficial, we conduct a standard empirical evaluation on PO domains and compare the runtime PO planners vs. transformation + TO planners

We should also do an evaluation that shows how often the erion works, i.e., in how many instances (per domain) we can say 'yes: translate!'

Results, graphs, etc here


\section{Modification}
(To reduce the preconditions and effects requires cutting depth wise (e.g. a sequence of tasks s.t.  add a, del a occurs in every possible sub branch)
If ALL methods are possible, you cant exclude the possibility of their prec/eff. Otherwise it would imply knowing which method to take, which makes no sense?)
The obvious solution to it's current deficiencies is: 
\begin{enumerate}
	\item When tasks need to be interleaved as part of it's solution, introduce new (totally ordered) methods that will allow this interleaving.
	If for example, The initial task network contains (AB, C') in that order. Then AB $\implies$ A, B.  and C' $\implies$ C.
	And the only solution is A, C, B. We can detect a cycle (as in the example above)
	Then when we detect the cycle between AB and C', we need a new method such that their parent (the initial task) $\implies$ A,C,B  in that order.  This one seems more impractical to find,
	since in practice some solutions might need interleaving of tasks that are very, very far apart in a TDG.
	
	\item Find a more accurate set of preconditions and effects for a given task.  
	E.g. if every possible decomposition of a given compound task that has $<$add a$>$ in action will also have $<$del a$>$ in a action after it, 
	then there is no need to include $<$add a$>$ as a possible effect of the compound task.
	E.g. another may be a precondition that is already met by an action before it. This precondition can be excluded from the compound tasks'??? Can it?
	
	
	Both will be difficult to find and remove in practice. But if we can remove some of these extraneous preconditions and/or effects, than extraneous orderings also disappear. This could reduce the number
	of cycles.
	
	Depending on the problem, even this will not be able to remove all cycles.  Some compound tasks will have \emph{different} 
	preconditions and effects depending	on the method(s) applied to decompose it to a sequence of primitive tasks. If any number of
	these is conflicting with another tasks, we will still have cycles.
	
	\item Because floating tasks can be executed where-ever, whenever there is such a floating task, we should produce
		
\end{enumerate}